---
title: "R Function Cheat Sheet"
author: "Shunkei Kakimoto"
output:
  html_document:
    number_sections: yes
    theme: flatly
    toc_float: yes
    toc: yes
    toc_depth: 2
geometry: margin=1in
---

```{r setup, include=FALSE}
library(knitr)
library(here)

# here::i_am("Dropbox/R-project/R-functions/GitControlled/General/R-func-cheat-sheet.rmd") 

# opts_knit$set(root.dir = "")
# opts_knit$set(root.dir = here())

knitr::opts_chunk$set(
  echo = TRUE,
  cache = FALSE,
  eval = FALSE, 
  comment = NA,
  message = FALSE,
  warning = FALSE,
  tidy = FALSE,
  cache.lazy = FALSE,
  #--- figure ---#
  dpi = 400,
  fig.width = 7.5,
  fig.height = 5,
  out.width = "750px",
  out.height = "500px"
)

# /*===== Basic Packages  =====*/
# /*---- Data Wrangling ----*/
library(data.table)
library(tidyverse)
library(DescTools)
library(maps)

# /*---- Visualization ----*/
library(RColorBrewer)
library(patchwork)
library(ggplot2)
library(ggthemes)
library(ggpubr)
library(viridis)
library(grid)
library(gridExtra)
library(GGally)

# /*---- Model Summary ----*/
library(stats)
library(modelsummary)
library(flextable)
library(officer)
library(officedown)
library(gt)

```

# Contents

## Topic
+ [Source all the functions in the Functions folder](#SourceFunction)
+ [Data Table Operation](#data_table)
  * Select columns using the pattern of their names
+ [Data Table merge](#data_table_merge)
+ [Manage strings](#ManageStrings)
+ [Basic Statics Summary](#SummaryTable)
+ [Check whether a column has NA values or not](#CheckNA)
+ [Find the percentage of NA](#FindNA)
+ [lubridate: Date-time data](#lubridate)
+ [Extract Subset of Data Frame Rows Containing NA](#ExtractNArows)
+ [Select rows that met some criterion by group](#selectgroup)
+ [Create new column by concatenating values in other columns](#concantenate)
+ [Change units](#ChangeUnits)
+ [Vectorization instead of looping with lapply](#Vectorization)
+ [Separate strings stored in a single column into multiple columns](#Separate)
+ [Storing a list within a data frame element](#store)
+ [Make a matrix of plots with a given data set](#ggally)
+ [parallel with loop function](#loop_parallel)
+ [Split data into a list of data by group](#split_data)


## Useful Packages:
+ tigris: to download shapefile
  * they also contains areas(m^2) information
  * download fips code data: `data(fips_codes)`
+ maps: ex) data(state.fips)
+ tidycensus: download census data
+ 

## A list of useful functions

### High
+ [**melt()**](#melt)
	* wide- to long-format data

+ [**dcast()**](#dcast)
	* long- to wide-format data 

+ [**download()**](#Downlowd): Downlaod files: downloader package

+ <span style="color:green">**na.omit(., cols = "usage")**</span>
	* remove NA from specific columns

+ [**as.formula()**](#formula)
## + [Storing a list within a data frame element]{#store}

+ [**eval()**](#eval)
	* evaluate an R expression in a specified environment

+ <span style="color:green">**as.numeric(as.vector(temp.df_for4[i,]))**</span>
	* * convert a list data to vector
+ <span style="color:green">**do.call(c, lapply(seq(to=2241, by=160), create.number_for4))**</span>x
	* stratified list data to a single list data

+ <span style="color:green">**unlist()**</span>
		-  this is useful when using lapply function

+ [***stringr***](#stringr)
	* <span style="color:green">str_detect()</span>
	* <span style="color:gren">str_pad(string, width, side = c("left", "right", "both"), pad = " ")</span>

+ <span style="color:green">**fread()**</span>: when you read a large file (ex. .txt)

+ [**intersect()**](#intersect)

<br>

### Low
+ <span style="color:blue">setcolorder()</span>
	* change the column order

+ <span style="color:blue">conv_unit(60, "ft", "m")</span>
	* Converts common units of measurement for a variety of dimensions

+ <span style="color:blue"> </span>

+ <span style="color:blue">tempfile()</span>

+ [**list.files()**](#listfiles)
	* produce charactervector of the names of files or directories in the named directory

+ <span style="color:blue">seq_length()</span>
	* e.g., seq_length(4) produces 1,2,3,4 

+ [**while loop**](#whileloop)

+ <span style="color:blue">require()</span>

+ <span style="color:blue">arrange()</span>
	*  ascending order
	* <span style="color:blue">arrange(, desc())</span>
		-  descending order

+ [**shift()**](#shift)
	* calculate lead/lag for cectors and lists

+ <span style="color:blue">nchar()</span>
	* character counting 

+ <span style="color:blue">summarise()</span>
	* is a convenient function to create a quick data frame

---

# Topics

## Data Table Operation {#data_table}

### Basic
+ `DT[[ ]]`
	* substruct single column from data.table as a vector using the name of the column

+ `rbindlist()`: combine a list of of the datasets into a single data.table
+ `rbindlist(tmax_by_county, idcol = "id")`   

+ `CJ( )`: from `data.table` package, (C)ross (J)oin. A data.table is formed from the cross product of the vectors. For example, 10 ids, and 100 dates, CJ returns a 1000 row table containing all the dates for all the ids. It gains sorted, which by default is TRUE for backwards compatibility. FALSE retains input order.

+ `fifelse()`: from `data.table` package. A faster and more robust replacement of `ifelse` fucntion.
	* the same syntax as `ifelse()` function
	* `fifelse(test, yes, no, na=NA)`

+ `data.table(, roll=TRUE)`: forward par of the rolling join

```{r}
data.table(, roll=TRUE): (f)
dt2[dt1, roll=TRUE, on=“joint_y”]
```

for each joint_y of dt1, finds joint_y of dt2 that is closest to joint_y of dt1 with the condition joint_y of dt1 >= joint_y of dt2

<br>

```{r}
CJ();
N <- 1000
T <- 10

reg_data <- 
  CJ(id = 1:N, t = 1:T) %>% 
  #=== individual FE ===#
  .[, ind_fe := rnorm(1), by = id] %>% 
  #=== year FE ===#
  .[, time_fe := rnorm(1), by = t] %>% 
  #=== covariates (independent) ===#
  .[, 
    `:=`(
      x_1 = rnorm(1), 
      x_2 = rnorm(1),
      x_3 = rnorm(1)
    ), 
    by = .(id, t)
  ]
```

### Data Table merge {#data_table_merge}
+ see [this](https://medium.com/analytics-vidhya/r-data-table-joins-48f00b46ce29)

```{r}
# Right outer join
big[small, on = .(id)]

# Inner join
small[big, on = .(id), nomatch = NULL]

```


### Select columns using a sequence of column  names

+ If you want to select columns with a sequence of column names

```{r}
report_res_allML[,select(.SD, Method, Model, Min.:Max., cumulative_pi_loss)]
```


### Calculate row-wise summation or mean

+ rowSums
+ rowMeans


```{r}
check_comp_LR <- 
  LR_5mi_y_owner[,.(nrd_owner_name, year)] %>%
  .[,index := 1] %>%
  dcast(nrd_owner_name ~ year, value.var = "index", , fill=0) %>%
  imputeTS::na_replace(fill = 0) %>%
  .[, num_y := rowSums(.SD), by = nrd_owner_name]
```


### Create a column by group


```{r}
  te_data <- test_data[, c("unique_subplot_id", var_ls, "aa_n", "opt_N", "yield", "X", "Y"), with = FALSE] %>%
    .[rep(1:nrow(.), each = length(N_levels)), ] %>%
    .[, rate := rep(N_levels, nrow(.) / length(N_levels))] %>%
    .[, yield_hat := predict(f_results, newdata = .[, c("rate", var_ls), with = FALSE])] %>%
    #--- Treatment effect calculation ---#
    .[, yield_base := .SD[rate==min(rate), yield_hat], by = .(unique_subplot_id)] %>%
    .[, te_base := yield_hat - yield_base] %>%
    .[, .(unique_subplot_id, rate, te_base)]
```

```{r}
dt <- data.table(X = c(1, 1, 2), Y = c(1, 1, 2))
dt[, Z := .N, by = .(X,Y)]


cdl_crop <- 
  cdl_value %>%
  .[,index := ifelse(MasterCat %in% ag_MasterCat, "ag", "nonag")] %>%
  .[,developed := ifelse(any(MasterCat %in% developed), 1, 0), by = .(id, year)]
```

<br>

<br>


### Subset by group

```{r}
cdl_crop[, .SD[any(index=="ag"&total_share<0.5)], by=.(id, year)]
```

The below is much faster

```{r}
cdl_crop[, if(any(index=="ag"&total_share<0.5)) .SD, by=.(id, year)]
```


<br>

<br>

### Select columns using the pattern of their names


```{r}

mydt[, .SD, .SDcols = names(mydt) %like% "bar|baz"]

names(test)[names(test) %like% "cdl"]

mydt[, grep(c("bar|baz"), names(mydt)), with = FALSE]
```




<br>

<br>

## Source all the functions in the Functions folder {#SourceFunction}

```{r}
fs::dir_ls(here("Codes", "Functions", "R"), full.names = TRUE) %>%
  lapply(., function(x) source(x))
```

<br>

<br>

## Manage strings {#ManageStrings}

+ `grep()` or `grepl()`: search for matches to argument `pattern` within each element of a character vectore
  * it returns locations of the target strings in the form of number of TRUE/FALSE 

+ `str_subset(string, pattern)` might be a good option

```{r}
grep(pattern= , x)
grepl(pattern= , x)
```

<br>

+ `gsub()`:
	* perform replacement of detail and all matches respectively remove all text before some symbol: 
	* `gsub(pattern, replacement, x, ignore.case = FALSE, perl = FALSE, fixed = FALSE, useBytes = FALSE)`


```{r}
# this remove all texts before “=“
gsub(".*=","","air_temperature_day=40446") 

text <- "40015"
# text <- "6047"
x <- sub("(.*)(.{3})", "\\1_\\2", text)
gsub("_.*", "", x) 
gsub(".*_", "", x) 


gsub(“20”, “”, as.character(2000:2019))


# replace “ “(space) with “_”(undervar)
new_names <- names(subset_prop_full) %>%
	 gsub(pattern = " ", replace="_") %>%
	 tolower()


# change column names by pattern
cdl_value_by_cat <- 
  cdl_value_by_cat_year %>%
  dcast(id + developed + total_ag_years ~ cat + year, value.var = "share", fill=0) %>%
  setnames(names(.), gsub(pattern = "cdl", replace="share", names(.)))
```

+ `substr()`

```{r}
substr("abcdef", 2, 4)
```

<br>

+ `str_extract()`: extract matching patterns from a string
+ `str_extract(string, pattern)`

```{r}
shopping_list <- c("apples x4", "bag of flour", "bag of sugar", "milk x2")

str_extract(variable,"[0-9]{1,5}")] 
```

<br>

+ `str_pad()`: pad a string 

<br>

+ `str_sub`: extract and replace rebstrings from a character vector

```{r}
x <- "some text in a string"
str_sub(x,-6,-1)
```

<br>

+ `str_split`: solit up a string into pieces


### stringr {#stringr}

+ `str_detect()`
  * Package "stringr"
  * Vectorised over string and pattern.
  * `str_detect(string, pattern, negate=FALSE)`

```{r}
tif_file_names <- list.files(path="./Data/HPA_sat_thickness_inputs" , pattern="*.tif", full.names=TRUE) %>% 
  .[!str_detect(.,'tif.')]

fruit <- c("apple", "banana", "pear", "pinapple")
str_detect(fruit, "a")       #ans. [1] TRUE TRUE TRUE TRUE
str_detect(fruit, "^a")      #ans. [1]  TRUE FALSE FALSE FALSE
str_detect(fruit, "a$")      #ans. [1] FALSE  TRUE FALSE FALSE
str_detect(fruit, "b")       #ans. [1] FALSE  TRUE FALSE FALSE
str_detect(fruit, "[aeiou]") #ans. [1] TRUE TRUE TRUE TRUE
```

+ `^` : now matches the start of each line
+ `$` : now matches the end of each line
+ `\A` : matches the start of the input
+ `\z` : matches the end of the input
+ `\Z` : matches the end of the input, but before the final line terminator, if exists



+ `str_replace()`
  * Replace matched pattern in a string
  * str_replace(string, pattern, replacement)

```{r}
names(reg_data_5mi) <- str_replace(names(reg_data_5mi), "_r", "")
```


+ `str_remove(string, pattern)`


```{r}
metros <-  get_acs(
  geography = "cbsa",
  variables = "DP03_0021P",
  summary_var = "B01003_001",
  survey = "acs1",
  year = 2019
) %>%
  slice_max(summary_est, n = 20)


# first remove all the text after the first dash, then remove the text after the first comma if no dash was originally present. 
metros %>%
  mutate(NAME = str_remove(NAME, "-.*$")) %>%
  mutate(NAME = str_remove(NAME, ",.*$")) %>%
  ggplot(aes(y = reorder(NAME, estimate), x = estimate)) + 
  geom_col()
```


```{r}
maine <- get_decennial(
  state = "Maine",
  geography = "county",
  variables = c(totalpop = "P1_001N"),
  year = 2020
) %>%
  arrange(desc(value))

maine_income <- get_acs(
  state = "Maine",
  geography = "county",
  variables = c(hhincome = "B19013_001"),
  year = 2020
) %>%
  mutate(NAME = str_remove(NAME, " County, Maine"))
```

<br>

<br>

## Basic Statics Summary {#SummaryTable}

+ modelsummary
+ gt

```{r}
datasummary_skim(full_dt[,.(total_value_calculated, assessed_total_value, market_total_value, appraised_total_value, sale_amount)],
	 title = "Quick overview of key variables in Full-data (all states)")

eq1 <- as.formula(paste(paste0(weather_var, collapse = "+"), "nrdname * (Mean + SD)",  sep="~"))

reg_data_new[,c("nrdname", weather_var, soil_var), with = FALSE] %>%
	datasummary(
		eq1,
		 # pr_in+tmmn_in ~  nrdname * (Mean + SD),
    data = .
    )

#- for row striping -#
custom_theme <- function(x, ...) {
    x %>% gt::opt_row_striping(row_striping = TRUE)
}
options("modelsummary_theme_gt" = custom_theme)
```

<br>

<br>

## Check whether a column has NA values or not {#CheckNA}

```{r}
sapply(temp, function(x) any(is.na(x)))
```

<br>

<br>

## Find the percentage of NA {#FindNA}

```{r}
sapply(data, function(x) sum(is.na(x)) / nrow(property_basic_meta))
```

<br>

<br>

## `lubridate`: Date-time data {#lubridate}

+ Look [[Here](https://lubridate.tidyverse.org/reference/as_date.html)]


```{r}
year = 2008
start_day <- (ymd(paste0(year, "-04-01")) - ymd("1900-01-01")) %>% as.numeric # nolint

end_day <- (ymd(paste0(year, "-09-30")) - ymd("1900-01-01")) %>% as.numeric 
```

Convert number to `ymd`

```{r}
dt_utc <- ymd_hms("2010-08-03 00:50:50")
dt_europe <- ymd_hms("2010-08-03 00:50:50", tz="Europe/London")
c(as_date(dt_utc), as.Date(dt_utc))
c(as_date(dt_europe), as.Date(dt_europe))

as_date(days_since_base, origin = "1900-01-01")

```

+ zoo package

```{r}
.[, date := as.Date.numeric(days_since_base, origin = "1900-01-01")] %>%
```

<br>

<br>

## Extract Subset of Data Frame Rows Containing NA {#ExtractNArows}


```{r}
data <- data.frame(x1 = c(3, NA, 3, 5, NA),    # Create data
                   x2 = c(NA, 1, 2, 3, 4),
                   x3 = c(7, NA, 4, 1, 2))
```

**Extract Rows with NA in Any Column**

```{r}
data[rowSums(is.na(data)) > 0, ]               # Missings in any row
```

**Extract Rows with NA in Specific Column**

```{r}
data[is.na(data$x1), ]   
```

<br>

<br>

## Select rows that met some criterion by group: {#selectgroup}

### groups which have at least one of a certain value
+ check [this](https://stackoverflow.com/questions/40825037/select-groups-which-have-at-least-one-of-a-certain-value)

```{r}
se_cdl_value <-
  cdl_value %>% 
  .[, .SD[any(Layer_1 %in% se_codes)], by = ID] %>%
  dcast(ID ~ type, value.var = "Layer_1") 
```

### groups where all have one of a certain value {#selectgroup}

```{r}
noag_cdl_value_ <- 
  cdl_value %>% 
  .[, .SD[all(Layer_1 %in% nonAg_codes)], by = ID] %>%
  dcast(ID ~ type, value.var = "Layer_1") 
```


<br>

<br>

## Create new column by concatenating values in other columns {#concantenate}

```{r}
test <- 
  ag_cdl_value %>% 
  # .[ID %in% c(1,6, 10),] %>%
  linkdata[., on = "MasterCat==Layer_1"] %>%
  .[, hist_crop :=  paste(unique(.SD[,MasterCat])%>% sort(.), collapse="," ), by = ID] %>%
  dcast(ID + hist_crop~ type, value.var = "MasterCat")
```

<br>

<br>

## Change units {#ChangeUnits}

+ `set_units()`  from `units` package [Here](https://cran.r-project.org/web/packages/units/vignettes/units.html)

```{r}
library(units)

dfw_data_for_model <- dfw_data %>%
  # number of people in each Census tract per square kilometer
  mutate(pop_density = as.numeric(set_units(total_populationE / st_area(.), "1/km2")),
         median_structure_age = 2018 - median_year_builtE) %>%
  select(!ends_with("M")) %>% 
  rename_with(.fn = ~str_remove(.x, "E$")) %>%
  na.omit()
```

<br>

<br>


## Vectorization instead of looping with lapply {#Vectorization}


```{r}
sim_par <- function(i, var_ls, reg_data, test_data, N_levels) {
  print(paste0("working on ", i, " th iteration."))
  # i = 1; var_ls = c("alpha", "beta", "ymax")
  # reg_data = train_dt; test_data = test_dt; N_levels = N_levels

  # /*----------------------------------*/
  #' ## run ML analyses
  # /*----------------------------------*/

  #--- all the cases to consider ---#
  case_data <- 
    tibble(
      Method = c("CF_base", "BRF", "RF")    
    )

  results_data <- 
    case_data %>%
      mutate(
        opt_N_data = future_lapply(
          seq_len(nrow(.)),
          function(x) {
            ### === apply various methods to get optimal N ===###
            get_opt_N(
              reg_data = reg_data,
              test_data = test_data,
              var_ls = var_ls,
              rates_ls = N_levels,
              Method = .$Method[[x]]
            )
          },
        future.seed = TRUE
      )
    )%>%
    unnest(., cols= "opt_N_data")%>%
    data.table()

  return(results_data)
     
}
```

```{r}
test <- 
  tibble(
    type = 2008:2010
    ) %>%
  mutate(
    cdl = mclapply(
      seq_len(nrow(.)),
      function(x){ 
        terra::extract(
              rast(here(paste0("Shared/Data/H&K/CDL/cdl_",.$type[[x]],".tif"))),
              vect(land_dt_unq_sf)
            ) %>%
            data.table() %>%
            cbind(., land_dt_unq[,.(X, Y)])
        },
        mc.cores = 4
      )
  )

unnest(test, cdl) %>% data.table()



get_cdl <- function(year){
            terra::extract(
              rast(here(paste0("Shared/Data/H&K/CDL/cdl_",year,".tif"))),
              vect(land_dt_unq_sf)
            ) %>%
            data.table() %>%
            .[,type := paste0("cdl",year)] %>%
            cbind(., land_dt_unq[,.(X, Y)])
          }

test <- 
  tibble(
    type = 2008:2010
    ) %>%
  mutate(
    cdl = mclapply(
      seq_len(nrow(.)),
      function(x){ 
        terra::extract(
              rast(here(paste0("Shared/Data/H&K/CDL/cdl_",.$type[[x]],".tif"))),
              vect(land_dt_unq_sf)
            ) %>%
            data.table() %>%
            cbind(., land_dt_unq[,.(X, Y)])
        },
        mc.cores = 4
      )
  )


test <- 
  tibble(
    type = 2008:2012
    ) %>%
  rowwise() %>%
  mutate(
    cdl = list(get_cdl(year=type))
  )
```

<br>

<br>


## Separate strings stored in a single column into multiple columns {#Separate}


```{r}
df <- data.frame(x = c(NA, "x.y", "x.z", "y.z"))
df %>% separate(x, c("A", "B"))
```

```{r}
separate(NAME, c("block", "BrockGroup", "CensusTract", "County", "State"), sep=", ") %>%
```


<br>

<br>


## Storing a list within a data frame element {#store}

```{r}
dt <- 
  tibble(
    id = 1:2,
    vec = st_touches(nc)[1:2]
    )


dt <- data.frame(
  id = seq_len(nrow(nc))
  )
dt$vec <- st_touches(nc)


dt <- data.table(
  # id = seq_len(nrow(nc))
  id = 1:5,
  vec =st_touches(nc)[1:5]
  )
```


## Select first element of nested list

```{r}
x = list(list(1,2), list(3,4), list(5,6))

lapply(x, `[[`, 1)


map(x, 1)
```


## Make a matrix of plots with a given data set {#ggally}

```{r}
GGally::ggpairs(
  data = analysis_data[,.(nnf, population)],
  # lower = list(continuous = wrap("points", size=0.5)),
  diag= list(continuous="barDiag"),
  title = "Scatterplot matrix of the Weather Data"
  )
```



## Parallel with loop function {#loop_parallel}

```{r}
library(foreach)
library(future)
library(doFuture)
plan(multisession) # Tells future package to use multiple cores on your computer.

# Without doRNG package, random numbers in parallel sessions might be equal.
library(doRNG) # random number generator for parallel processing
registerDoFuture()
registerDoRNG(seed=580724) # This is where you set the random seed when 
                           # using parallel processing.

asymp.ci <- 
  foreach(b = 1:B, .combine=rbind) %dopar% {
    # for example, 
    # b=1
    # --- Generating data --- #
    a7 <- new.data(n, beta)
    # --- run a regression (with the correct specification)--- #
    reg <- lm(Y~X1+X2+D+I(D*X1), data=a7)
    # --- compute confidence interval --- #
    this.ci <- coefci(reg, level=0.95, vcov.=vcovHC, type=type)[which.coef, ]
    this.ci  # Last thing goes into next row of asymp.ci.
}
```


## Split data into a list of data by group {#split_data}

```{r}
  ls_stn_sf_days <- 
    stn_sf %>%
    group_by(time) %>%
    group_map(~.x, .keep = TRUE)
```

---

# A list of useful functions

## melt() {#melt}
+ wide- to long-format data

```{r}
DT.m1 = melt(DT, id.vars = c("family_id", "age_mother"),
                measure.vars = c("dob_child1", "dob_child2", "dob_child3"))   

melt(id.vars = "ID", variable.name = "day")

  melt(
    copy_all.stats, 
    id.vars = c("var_long", "var_short")
    variable.name = ,
    value.name
    )   
```

+ **Note**: 
	* measure.vars specify the set of columns we would like to collapse together.
	* id.vars specifies the variables that we don't change
	* By default, variable column is of type factor. Set variable.factor argument to FALSE if you’d like to return a character vector instead.


## dcast() {#dcast}
+ long- to wide-format data 

```{r}
dcast(DT.m1, family_id + age_mother ~ child, value.var = "dob", fill=0)
```

+ **Note**:
	* LHS represents the id vars 
	* RHS the measure vars
	* value.var denotes the column to be filled in with while casting to wide format
	-> id vars ~ measure vars


## intersect() {#intersect}
+ Calculates the intersection of subsets of a probability space. Comparisons are made row-wise, so that in the data frame case, intersect(A,B) is a data frame with those rows that are both in A and in B.

```{r}
S <- cards()
A <- subset(S, suit == "Heart")
B <- subset(S, rank == "A" )
intersect(A, B)
```


## formula()

```{r}
as.formula()

eq1 <- as.formula(paste(paste0(weather_var, collapse = "+"), "nrdname * (Mean + SD)",  sep="~"))
```

## eval() {#eval}

```{r}
eval(parse(text=paste('data[,treat:=',treat_var,']',sep="")))
```

## lapply vs sapply
+ `lapply()` returns outputs as a list
+ `sapply()`returns outputs as a vector

<br>

Suppose you create a function that returns multiple object as a list. Then, after all iterations, you'll get a final results as a list that contains multiple object within it. If you want to retrieve one of them, `sapply` function is useful.

```{r}
sapply(all_results,'[',1)
sapply(all_results,'[',2) %>% rbindlist()

cf <- sapply(all_results,'[',1)
tau_all <- sapply(all_results,'[',2) %>% rbindlist()
vi_all <- sapply(all_results,'[',3) %>% rbindlist() %>% 
	.[,variable:=factor(variable,levels=var_ls)] %>% 
    dcast(variable~trt,value.var ='vi')
```


## download() {#Downlowd}

+ `download()` from `downloader` package

```{r}
download( url = , destfile = , mode = ‘web’ )
```

<br>


## list.files() {#listfiles}

produce charactervector of the names of files or directories in the named directory

```{r}
tif_file_names <- list.files(path="./Data/HPA_sat_thickness_inputs" , pattern="*.tif", full.names=TRUE) %>% 
  .[!str_detect(.,'tif.')]
```


## While loop {#whileloop}

A loop is a statement function that keeps running until a condition is satisfied.

+ usage: 

```{r}
while (condition){
                Exp
        }
```

For exampel: 

```{r}
total <- 0
    number <- as.integer(readline(prompt="Please Enter any integer Value below 10:  "))

    whiel(number <= 10) {
    total = total + number
    number = number + 1
    }
```


## shift() {#shift}

```{r}
.[, tau_stepwise := yield_hat - shift(yield_hat), by = unique_cell_id]
```








